{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plaidml.keras\n",
    "plaidml.keras.install_backend()\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from code.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP w/ Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = load(\"data/largefiles/x_feat.pkl\")\n",
    "y = load(\"data/largefiles/y_onehot.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127284, 50) (127284, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 19:44:56.543683 4562654656 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0819 19:44:56.575459 4562654656 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0819 19:44:56.586928 4562654656 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0819 19:44:56.607791 4562654656 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0819 19:44:56.615803 4562654656 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0819 19:44:56.793473 4562654656 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0819 19:44:56.816644 4562654656 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 5,202\n",
      "Trainable params: 5,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, activation='tanh', input_shape=(50,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 89098 samples, validate on 38186 samples\n",
      "Epoch 1/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1297 - acc: 0.9550 - val_loss: 0.1297 - val_acc: 0.9547\n",
      "Epoch 2/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1298 - acc: 0.9553 - val_loss: 0.1295 - val_acc: 0.9547\n",
      "Epoch 3/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1297 - acc: 0.9557 - val_loss: 0.1331 - val_acc: 0.9543\n",
      "Epoch 4/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1303 - acc: 0.9552 - val_loss: 0.1284 - val_acc: 0.9551\n",
      "Epoch 5/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1302 - acc: 0.9552 - val_loss: 0.1286 - val_acc: 0.9549\n",
      "Epoch 6/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1303 - acc: 0.9550 - val_loss: 0.1282 - val_acc: 0.9546\n",
      "Epoch 7/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1299 - acc: 0.9553 - val_loss: 0.1290 - val_acc: 0.9546\n",
      "Epoch 8/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1296 - acc: 0.9553 - val_loss: 0.1280 - val_acc: 0.9556\n",
      "Epoch 9/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1292 - acc: 0.9553 - val_loss: 0.1278 - val_acc: 0.9550\n",
      "Epoch 10/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1288 - acc: 0.9554 - val_loss: 0.1312 - val_acc: 0.9541\n",
      "Epoch 11/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1290 - acc: 0.9556 - val_loss: 0.1273 - val_acc: 0.9559\n",
      "Epoch 12/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1291 - acc: 0.9553 - val_loss: 0.1271 - val_acc: 0.9561\n",
      "Epoch 13/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1292 - acc: 0.9555 - val_loss: 0.1284 - val_acc: 0.9556\n",
      "Epoch 14/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1294 - acc: 0.9554 - val_loss: 0.1271 - val_acc: 0.9555\n",
      "Epoch 15/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1291 - acc: 0.9557 - val_loss: 0.1276 - val_acc: 0.9558\n",
      "Epoch 16/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1277 - acc: 0.9559 - val_loss: 0.1278 - val_acc: 0.9558\n",
      "Epoch 17/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1283 - acc: 0.9562 - val_loss: 0.1284 - val_acc: 0.9550\n",
      "Epoch 18/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1287 - acc: 0.9556 - val_loss: 0.1277 - val_acc: 0.9556\n",
      "Epoch 19/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1283 - acc: 0.9563 - val_loss: 0.1272 - val_acc: 0.9554\n",
      "Epoch 20/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1276 - acc: 0.9563 - val_loss: 0.1275 - val_acc: 0.9558\n",
      "Epoch 21/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1273 - acc: 0.9562 - val_loss: 0.1266 - val_acc: 0.9563\n",
      "Epoch 22/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1283 - acc: 0.9561 - val_loss: 0.1279 - val_acc: 0.9547\n",
      "Epoch 23/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1281 - acc: 0.9561 - val_loss: 0.1279 - val_acc: 0.9555\n",
      "Epoch 24/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1279 - acc: 0.9560 - val_loss: 0.1301 - val_acc: 0.9548\n",
      "Epoch 25/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1275 - acc: 0.9557 - val_loss: 0.1286 - val_acc: 0.9550\n",
      "Epoch 26/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1273 - acc: 0.9565 - val_loss: 0.1265 - val_acc: 0.9564\n",
      "Epoch 27/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1277 - acc: 0.9562 - val_loss: 0.1260 - val_acc: 0.9563\n",
      "Epoch 28/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1273 - acc: 0.9558 - val_loss: 0.1258 - val_acc: 0.9558\n",
      "Epoch 29/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1274 - acc: 0.9563 - val_loss: 0.1278 - val_acc: 0.9553\n",
      "Epoch 30/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1272 - acc: 0.9558 - val_loss: 0.1258 - val_acc: 0.9561\n",
      "Epoch 31/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1268 - acc: 0.9561 - val_loss: 0.1258 - val_acc: 0.9567\n",
      "Epoch 32/50\n",
      "89098/89098 [==============================] - 1s 9us/step - loss: 0.1269 - acc: 0.9564 - val_loss: 0.1273 - val_acc: 0.9566\n",
      "Epoch 33/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1266 - acc: 0.9563 - val_loss: 0.1267 - val_acc: 0.9554\n",
      "Epoch 34/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1265 - acc: 0.9563 - val_loss: 0.1272 - val_acc: 0.9561\n",
      "Epoch 35/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1266 - acc: 0.9564 - val_loss: 0.1254 - val_acc: 0.9568\n",
      "Epoch 36/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1269 - acc: 0.9563 - val_loss: 0.1257 - val_acc: 0.9564\n",
      "Epoch 37/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1269 - acc: 0.9567 - val_loss: 0.1268 - val_acc: 0.9556\n",
      "Epoch 38/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1265 - acc: 0.9569 - val_loss: 0.1265 - val_acc: 0.9566\n",
      "Epoch 39/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1270 - acc: 0.9563 - val_loss: 0.1269 - val_acc: 0.9554\n",
      "Epoch 40/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1266 - acc: 0.9560 - val_loss: 0.1258 - val_acc: 0.9564\n",
      "Epoch 41/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1269 - acc: 0.9564 - val_loss: 0.1260 - val_acc: 0.9563\n",
      "Epoch 42/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1266 - acc: 0.9565 - val_loss: 0.1254 - val_acc: 0.9566\n",
      "Epoch 43/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1263 - acc: 0.9563 - val_loss: 0.1271 - val_acc: 0.9558\n",
      "Epoch 44/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1265 - acc: 0.9567 - val_loss: 0.1259 - val_acc: 0.9563\n",
      "Epoch 45/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1261 - acc: 0.9562 - val_loss: 0.1253 - val_acc: 0.9560\n",
      "Epoch 46/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1265 - acc: 0.9561 - val_loss: 0.1254 - val_acc: 0.9564\n",
      "Epoch 47/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1268 - acc: 0.9557 - val_loss: 0.1281 - val_acc: 0.9555\n",
      "Epoch 48/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1264 - acc: 0.9564 - val_loss: 0.1255 - val_acc: 0.9567\n",
      "Epoch 49/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1268 - acc: 0.9563 - val_loss: 0.1260 - val_acc: 0.9556\n",
      "Epoch 50/50\n",
      "89098/89098 [==============================] - 1s 8us/step - loss: 0.1258 - acc: 0.9568 - val_loss: 0.1256 - val_acc: 0.9567\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.12564320442293248\n",
      "Test accuracy: 0.9567118839365213\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
