{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\program files\\python37\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from code.modelhelper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "N_CLASS = 2\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 630), (60000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.load(\"data/xy/x_feat_630.npz\")[\"arr_0\"]\n",
    "y = np.load(\"data/xy/y_onehot_45_15.npy\")\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP w/ Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "m1_input (InputLayer)        [(None, 630)]             0         \n",
      "_________________________________________________________________\n",
      "m1_dense_1 (Dense)           (None, 50)                31550     \n",
      "_________________________________________________________________\n",
      "m1_dense_2 (Dense)           (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "m1_dense_3 (Dense)           (None, 150)               15150     \n",
      "_________________________________________________________________\n",
      "m1_dense_4 (Dense)           (None, 200)               30200     \n",
      "_________________________________________________________________\n",
      "m1_dropout_1 (Dropout)       (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "m1_output (Dense)            (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 82,402\n",
      "Trainable params: 82,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_input = Input(shape=(x.shape[1], ), name=\"m1_input\")\n",
    "H = Dense(50, activation='relu', name=\"m1_dense_1\")(model_input)\n",
    "H = Dense(100, activation=\"relu\", name=\"m1_dense_2\")(H)\n",
    "H = Dense(150, activation=\"relu\", name=\"m1_dense_3\")(H)\n",
    "H = Dense(200, activation=\"relu\", name=\"m1_dense_4\")(H)\n",
    "H = Dropout(0.4, name=\"m1_dropout_1\")(H)\n",
    "model_output = Dense(N_CLASS, activation=\"softmax\", name=\"m1_output\")(H)\n",
    "\n",
    "model = Model(inputs=model_input, outputs=model_output)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='nadam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[es]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "y_pred_model = model.predict(x_test.astype(\"float\"))\n",
    "y_pred = to_bin(y_pred_model)\n",
    "print(\"Test recall: {}\".format(recall(y_test, y_pred)))\n",
    "\n",
    "y_test0 = to_1D(y_test)\n",
    "y_pred0 = to_1D(y_pred)\n",
    "print(confusion_matrix(y_test0, y_pred0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Test\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"models/dl/m1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"es\": es,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 10-fold cross validation:\n",
      "    Validation 01 of 10 ... done [21.78s]\n",
      "    Validation 02 of 10 ... done [4.04s]\n",
      "    Validation 03 of 10 ... done [5.72s]\n",
      "    Validation 04 of 10 ... done [6.34s]\n",
      "    Validation 05 of 10 ... done [4.93s]\n",
      "    Validation 06 of 10 ... done [4.56s]\n",
      "    Validation 07 of 10 ... done [5.69s]\n",
      "    Validation 08 of 10 ... done [4.74s]\n",
      "    Validation 09 of 10 ... done [5.72s]\n",
      "    Validation 10 of 10 ... done [4.61s]\n"
     ]
    }
   ],
   "source": [
    "scores = kfold(model, model_params, x, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\numba\\ir_utils.py:1959: NumbaPendingDeprecationWarning: \u001b[1m\n",
      "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'scores_dict' of function 'scores_dict_to_array'.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
      "\u001b[1m\n",
      "File \"code\\modelhelper.py\", line 187:\u001b[0m\n",
      "\u001b[1m@jit\n",
      "\u001b[1mdef scores_dict_to_array(scores_dict):\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.95783333, 0.958     , 0.955     , 0.95916667, 0.96066667,\n",
       "        0.96066667, 0.96466667, 0.96116667, 0.96216667, 0.961     ],\n",
       "       [0.95315985, 0.97101449, 0.94675419, 0.95718433, 0.97505669,\n",
       "        0.94142555, 0.97079772, 0.95577746, 0.95020188, 0.98026835],\n",
       "       [0.87092391, 0.85608608, 0.86822742, 0.87641196, 0.86403215,\n",
       "        0.89710827, 0.88852673, 0.88682991, 0.90223642, 0.85596141],\n",
       "       [0.01391343, 0.00842012, 0.01620422, 0.0131257 , 0.00732194,\n",
       "        0.01839131, 0.00918047, 0.01381154, 0.01668546, 0.00549571]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = scores_dict_to_array(scores)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"cv/m1_cv.npy\", arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
